# -*- coding: utf-8 -*-
import os, re, time, random, json, argparse
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

PAGE_LOAD_TIMEOUT = 90

def build_driver():
    opts = Options()
    # à¸ªà¸³à¸«à¸£à¸±à¸š GitHub Actions / headless
    opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument("--window-size=1365,900")
    ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125 Safari/537.36"
    opts.add_argument(f"--user-agent={ua}")

    # à¹ƒà¸Šà¹‰ Chrome à¸—à¸µà¹ˆ action à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰
    chrome_path = os.getenv("CHROME_PATH") or os.getenv("GOOGLE_CHROME_BIN")
    if chrome_path:
        opts.binary_location = chrome_path

    # à¸–à¹‰à¸²à¸¡à¸µ WEBDRIVER_PATH à¹ƒà¸«à¹‰à¸Šà¸µà¹‰à¹ƒà¸Šà¹‰à¸•à¸±à¸§à¸™à¸±à¹‰à¸™ (à¸•à¸£à¸‡à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™à¸à¸±à¸š Chrome à¹à¸™à¹ˆà¸™à¸­à¸™)
    driver_path = os.getenv("WEBDRIVER_PATH")
    if driver_path:
        service = Service(driver_path)
        driver = webdriver.Chrome(service=service, options=opts)
    else:
        # à¹„à¸¡à¹ˆà¸¡à¸µ -> à¹ƒà¸«à¹‰ Selenium Manager à¹€à¸¥à¸·à¸­à¸à¹ƒà¸«à¹‰à¹€à¸­à¸‡
        driver = webdriver.Chrome(options=opts)

    driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
    return driver

def close_popup_if_any(driver):
    try:
        time.sleep(0.8)
        for sel in ['#btnWarning', '.modal [data-bs-dismiss="modal"]', '.modal .btn-close', '.swal2-confirm']:
            for el in driver.find_elements(By.CSS_SELECTOR, sel):
                try:
                    if el.is_displayed() and el.is_enabled():
                        el.click(); time.sleep(0.4)
                except: pass
    except: pass

def go_home_and_search(driver, tax_id: str):
    driver.get("https://datawarehouse.dbd.go.th/index")
    wait = WebDriverWait(driver, 40)
    close_popup_if_any(driver)
    sb = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "input#key-word.form-control")))
    sb.clear(); sb.send_keys(tax_id); time.sleep(0.2); sb.send_keys(Keys.ENTER)

    # à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸£à¸­à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¸«à¸™à¹‰à¸²à¹‚à¸›à¸£à¹„à¸Ÿà¸¥à¹Œà¹€à¸¥à¸¢
    try:
        wait.until(EC.presence_of_element_located((By.XPATH, "//h4[contains(.,'à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥')]")))
        return
    except TimeoutException:
        pass

    # à¸–à¹‰à¸²à¸­à¸¢à¸¹à¹ˆà¸«à¸™à¹‰à¸²à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ à¹ƒà¸«à¹‰à¸„à¸¥à¸´à¸ "à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”" à¸­à¸±à¸™à¹à¸£à¸
    for txt in ["à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”", "à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”", "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥"]:
        links = driver.find_elements(By.XPATH, f"//a[contains(.,'{txt}')]")
        if links:
            links[0].click()
            break

def wait_profile_loaded(driver):
    wait = WebDriverWait(driver, 40)
    wait.until(EC.presence_of_element_located((By.XPATH, "//h4[contains(.,'à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥')]")))
    time.sleep(0.8)

def extract_text_after_label(soup: BeautifulSoup, label: str) -> str:
    label_div = soup.find(lambda t: t.name == "div" and t.get_text(strip=True) == label)
    if not label_div: return ""
    parent = label_div.parent
    if parent:
        cols = parent.find_all("div", recursive=False)
        for i, c in enumerate(cols):
            if c is label_div and i + 1 < len(cols):
                return cols[i + 1].get_text(" ", strip=True)
    nxt = label_div.find_next_sibling("div")
    return nxt.get_text(" ", strip=True) if nxt else ""

def parse_profile_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    h3 = soup.find("h3")
    h4 = soup.find("h4")
    name = re.sub(r"^à¸Šà¸·à¹ˆà¸­à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥\s*:\s*", "", h3.get_text(" ", strip=True) if h3 else "") or "-"
    reg  = re.sub(r"^à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥:\s*", "", h4.get_text(" ", strip=True) if h4 else "") or "-"
    status_text = extract_text_after_label(soup, "à¸ªà¸–à¸²à¸™à¸°à¸™à¸´à¸•à¸´à¸šà¸¸à¸„à¸„à¸¥") or "-"
    reg_date    = extract_text_after_label(soup, "à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸ˆà¸±à¸”à¸•à¸±à¹‰à¸‡") or "-"
    capital     = extract_text_after_label(soup, "à¸—à¸¸à¸™à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™") or "-"
    biz_group   = extract_text_after_label(soup, "à¸à¸¥à¸¸à¹ˆà¸¡à¸˜à¸¸à¸£à¸à¸´à¸ˆ") or "-"
    biz_size    = extract_text_after_label(soup, "à¸‚à¸™à¸²à¸”à¸˜à¸¸à¸£à¸à¸´à¸ˆ") or "-"
    address     = extract_text_after_label(soup, "à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¸ªà¸³à¸™à¸±à¸à¸‡à¸²à¸™à¹à¸«à¹ˆà¸‡à¹ƒà¸«à¸à¹ˆ") or "-"

    directors = "-"
    h5_list = soup.find_all("h5", string=lambda s: s and "à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸à¸£à¸£à¸¡à¸à¸²à¸£" in s)
    if h5_list:
        body = h5_list[0].find_next("div", class_="card-body")
        if body:
            lis = [li.get_text(" ", strip=True).strip(" /") for li in body.find_all("li")]
            if lis: directors = ", ".join(lis)

    tsic1_code_name, tsic1_obj = "-", "-"
    h5_tsic1 = soup.find("h5", string=lambda s: s and "à¸›à¸£à¸°à¹€à¸ à¸—à¸˜à¸¸à¸£à¸à¸´à¸ˆà¸•à¸­à¸™à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™" in s)
    if h5_tsic1:
        body = h5_tsic1.find_next("div", class_="card-body")
        if body:
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="à¸›à¸£à¸°à¹€à¸ à¸—à¸˜à¸¸à¸£à¸à¸´à¸ˆ")
            if lab and lab.find_next_sibling("div"): tsic1_code_name = lab.find_next_sibling("div").get_text(" ", strip=True)
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ")
            if lab and lab.find_next_sibling("div"): tsic1_obj = lab.find_next_sibling("div").get_text(" ", strip=True)

    tsic2_code_name, tsic2_obj = "-", "-"
    h5_tsic2 = soup.find("h5", string=lambda s: s and "à¸›à¸£à¸°à¹€à¸ à¸—à¸˜à¸¸à¸£à¸à¸´à¸ˆà¸—à¸µà¹ˆà¸ªà¹ˆà¸‡à¸‡à¸šà¸à¸²à¸£à¹€à¸‡à¸´à¸™à¸›à¸µà¸¥à¹ˆà¸²à¸ªà¸¸à¸”" in s)
    if h5_tsic2:
        body = h5_tsic2.find_next("div", class_="card-body")
        if body:
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="à¸›à¸£à¸°à¹€à¸ à¸—à¸˜à¸¸à¸£à¸à¸´à¸ˆ")
            if lab and lab.find_next_sibling("div"): tsic2_code_name = lab.find_next_sibling("div").get_text(" ", strip=True)
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ")
            if lab and lab.find_next_sibling("div"): tsic2_obj = lab.find_next_sibling("div").get_text(" ", strip=True)

    return {
        "à¸Šà¸·à¹ˆà¸­": name, "à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™": reg, "à¸ªà¸–à¸²à¸™à¸°": status_text, "à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™": reg_date,
        "à¸—à¸¸à¸™à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™": capital, "à¸à¸¥à¸¸à¹ˆà¸¡à¸˜à¸¸à¸£à¸à¸´à¸ˆ": biz_group, "à¸‚à¸™à¸²à¸”à¸˜à¸¸à¸£à¸à¸´à¸ˆ": biz_size,
        "à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¸ªà¸³à¸™à¸±à¸à¸‡à¸²à¸™à¹ƒà¸«à¸à¹ˆ": address, "à¸à¸£à¸£à¸¡à¸à¸²à¸£": directors,
        "TSIC à¸•à¸­à¸™à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™": tsic1_code_name, "à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸•à¸­à¸™à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™": tsic1_obj,
        "TSIC à¸¥à¹ˆà¸²à¸ªà¸¸à¸”": tsic2_code_name, "à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”": tsic2_obj,
    }

def scrape_one_id(driver, tax_id: str):
    go_home_and_search(driver, tax_id)
    wait_profile_loaded(driver)
    try:
        WebDriverWait(driver, 12).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".tab1")))
        html = driver.find_element(By.CSS_SELECTOR, ".tab1").get_attribute("innerHTML") or driver.page_source
    except:
        html = driver.page_source
    data = parse_profile_html(html)
    return None if not data.get("à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™") or data["à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™"] in ("-","") else data

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--tax-id", default=os.getenv("TAX_ID", "0135563016845"))
    args = ap.parse_args()
    tax_id = re.sub(r"\D", "", args.tax_id)
    if not re.fullmatch(r"\d{13}", tax_id):
        print("âŒ à¹ƒà¸ªà¹ˆà¹€à¸¥à¸‚à¸œà¸¹à¹‰à¹€à¸ªà¸µà¸¢à¸ à¸²à¸©à¸µ 13 à¸«à¸¥à¸±à¸à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡"); return

    driver = build_driver()
    try:
        print(f"ðŸ”Ž à¸„à¹‰à¸™à¸«à¸²à¹€à¸¥à¸‚à¸ à¸²à¸©à¸µ: {tax_id}")
        data = scrape_one_id(driver, tax_id)
        if not data:
            print("âš ï¸  à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥/à¸­à¹ˆà¸²à¸™à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ"); return
        print("âœ… à¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥:")
        print(json.dumps(data, ensure_ascii=False, indent=2))
    finally:
        try: driver.quit()
        except: pass

if __name__ == "__main__":
    time.sleep(random.uniform(1.2, 2.5))  # à¸à¸±à¸™ throttle à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™
    main()
