# -*- coding: utf-8 -*-
import os, re, time, random, json, argparse
from datetime import datetime, timezone
from urllib.parse import urljoin
from bs4 import BeautifulSoup

# Selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    TimeoutException, ElementClickInterceptedException, StaleElementReferenceException
)

# Google Sheets
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.errors import HttpError

PAGE_LOAD_TIMEOUT = 90
BASE = "https://datawarehouse.dbd.go.th"

# ========== Utils ==========
def canon_tax_id(x: str) -> str:
    """‡∏ó‡∏≥‡πÄ‡∏•‡∏Ç‡∏ú‡∏π‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏†‡∏≤‡∏©‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏° 0 ‡∏ã‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö 13 ‡∏´‡∏•‡∏±‡∏Å"""
    t = re.sub(r"\D", "", str(x or ""))
    return t.zfill(13) if t else ""

def retry_backoff(fn, max_attempts=5, retriable_status=(429, 403)):
    """‡∏£‡∏±‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Google API ‡∏û‡∏£‡πâ‡∏≠‡∏° backoff ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
    for attempt in range(max_attempts):
        try:
            return fn()
        except HttpError as e:
            code = getattr(e.resp, "status", None)
            if code in retriable_status:
                sleep_time = (2 ** attempt) + random.random()
                print(f"‚è≥ quota/backoff (HTTP {code}) ‚Üí sleep {sleep_time:.1f}s")
                time.sleep(sleep_time)
                continue
            raise

# ========== Selenium helpers ==========
def build_driver():
    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument("--window-size=1365,900")
    ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125 Safari/537.36"
    opts.add_argument(f"--user-agent={ua}")
    chrome_path = os.getenv("CHROME_PATH") or os.getenv("GOOGLE_CHROME_BIN")
    if chrome_path:
        opts.binary_location = chrome_path
    driver = webdriver.Chrome(options=opts)  # Selenium Manager ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ chromedriver ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á
    driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
    return driver

def close_popup_if_any(driver):
    try:
        time.sleep(0.6)
        sels = ['#btnWarning', '.modal [data-bs-dismiss="modal"]', '.modal .btn-close', '.swal2-confirm']
        for sel in sels:
            for el in driver.find_elements(By.CSS_SELECTOR, sel):
                try:
                    if el.is_displayed() and el.is_enabled():
                        el.click(); time.sleep(0.3)
                except Exception:
                    pass
    except Exception:
        pass

def safe_open_link(driver, el):
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏°‡πâ‡∏°‡∏µ overlay"""
    href = None
    try:
        href = el.get_attribute("href")
    except StaleElementReferenceException:
        pass
    if href:
        driver.get(urljoin(BASE, href))
        return True
    try:
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", el)
        time.sleep(0.15)
        el.click()
        return True
    except ElementClickInterceptedException:
        try:
            driver.execute_script("arguments[0].click();", el)
            return True
        except Exception:
            return False
    except Exception:
        return False

def go_home_and_search(driver, tax_id: str):
    driver.get(f"{BASE}/index")
    wait = WebDriverWait(driver, 40)
    close_popup_if_any(driver)
    sb = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "input#key-word.form-control")))
    sb.clear(); sb.send_keys(tax_id); time.sleep(0.2); sb.send_keys(Keys.ENTER)

    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    try:
        wait.until(EC.presence_of_element_located((By.XPATH, "//h4[contains(.,'‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•')]")))
        return
    except TimeoutException:
        pass

    # ‡∏´‡∏ô‡πâ‡∏≤ list ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    for label in ["‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", "‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"]:
        links = driver.find_elements(By.XPATH, f"//a[contains(.,'{label}')]")
        if links:
            close_popup_if_any(driver)
            if safe_open_link(driver, links[0]):
                return
            try:
                href = links[0].get_attribute("href")
                if href:
                    driver.get(urljoin(BASE, href))
                    return
            except Exception:
                pass

def wait_profile_loaded(driver):
    wait = WebDriverWait(driver, 40)
    wait.until(EC.presence_of_element_located((By.XPATH, "//h4[contains(.,'‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•')]")))
    time.sleep(0.6)

# ========== Parsing ==========
def extract_text_after_label(soup: BeautifulSoup, label: str) -> str:
    label_div = soup.find(lambda t: t.name == "div" and t.get_text(strip=True) == label)
    if not label_div: return ""
    parent = label_div.parent
    if parent:
        cols = parent.find_all("div", recursive=False)
        for i, c in enumerate(cols):
            if c is label_div and i + 1 < len(cols):
                return cols[i + 1].get_text(" ", strip=True)
    nxt = label_div.find_next_sibling("div")
    return nxt.get_text(" ", strip=True) if nxt else ""

def parse_profile_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    h3 = soup.find("h3"); h4 = soup.find("h4")
    name = re.sub(r"^‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•\s*:\s*", "", h3.get_text(" ", strip=True) if h3 else "") or "-"
    reg  = re.sub(r"^‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:\s*", "", h4.get_text(" ", strip=True) if h4 else "") or "-"
    status_text = extract_text_after_label(soup, "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•") or "-"
    reg_date    = extract_text_after_label(soup, "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏à‡∏±‡∏î‡∏ï‡∏±‡πâ‡∏á") or "-"
    capital     = extract_text_after_label(soup, "‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô") or "-"
    biz_group   = extract_text_after_label(soup, "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à") or "-"
    biz_size    = extract_text_after_label(soup, "‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à") or "-"
    address     = extract_text_after_label(soup, "‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà") or "-"

    directors = "-"
    h5_list = soup.find_all("h5", string=lambda s: s and "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£" in s)
    if h5_list:
        body = h5_list[0].find_next("div", class_="card-body")
        if body:
            lis = [li.get_text(" ", strip=True).strip(" /") for li in body.find_all("li")]
            if lis: directors = ", ".join(lis)

    tsic1_code_name, tsic1_obj = "-", "-"
    h5_tsic1 = soup.find("h5", string=lambda s: s and "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô" in s)
    if h5_tsic1:
        body = h5_tsic1.find_next("div", class_="card-body")
        if body:
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à")
            if lab and lab.find_next_sibling("div"): tsic1_code_name = lab.find_next_sibling("div").get_text(" ", strip=True)
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå")
            if lab and lab.find_next_sibling("div"): tsic1_obj = lab.find_next_sibling("div").get_text(" ", strip=True)

    tsic2_code_name, tsic2_obj = "-", "-"
    h5_tsic2 = soup.find("h5", string=lambda s: s and "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏õ‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î" in s)
    if h5_tsic2:
        body = h5_tsic2.find_next("div", class_="card-body")
        if body:
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à")
            if lab and lab.find_next_sibling("div"): tsic2_code_name = lab.find_next_sibling("div").get_text(" ", strip=True)
            lab = body.find(lambda t: t.name=="div" and t.get_text(strip=True)=="‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå")
            if lab and lab.find_next_sibling("div"): tsic2_obj = lab.find_next_sibling("div").get_text(" ", strip=True)

    return {
        "‡∏ä‡∏∑‡πà‡∏≠": name, "‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": reg, "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞": status_text, "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": reg_date,
        "‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": capital, "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": biz_group, "‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": biz_size,
        "‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏ç‡πà": address, "‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£": directors,
        "TSIC ‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": tsic1_code_name, "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": tsic1_obj,
        "TSIC ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": tsic2_code_name, "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î": tsic2_obj,
    }

def scrape_one_id(driver, tax_id: str):
    for attempt in range(2):
        go_home_and_search(driver, tax_id)
        try:
            wait_profile_loaded(driver)
            break
        except TimeoutException:
            if attempt == 1: raise
            time.sleep(1.2)

    try:
        WebDriverWait(driver, 12).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".tab1")))
        html = driver.find_element(By.CSS_SELECTOR, ".tab1").get_attribute("innerHTML") or driver.page_source
    except Exception:
        html = driver.page_source
    data = parse_profile_html(html)
    return None if not data.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô") or data["‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"] in ("-","") else data

# ========== Data / Sheets helpers ==========
HEADERS = [
    "tax_id","‡∏ä‡∏∑‡πà‡∏≠","‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô","‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞","‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô","‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô",
    "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à","‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à","‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏ç‡πà","‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£",
    "TSIC ‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô","‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô","TSIC ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î","‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
    "fetched_at_utc"
]

def read_tax_ids(path: str):
    ids = []
    if path and os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.split("#", 1)[0].strip()
                if not line:
                    continue
                m = re.search(r"\d{12,13}", line)  # ‡∏¢‡∏≠‡∏° 12‚Äì13 ‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡πâ‡∏ß normalize ‡∏ï‡πà‡∏≠
                if m:
                    ids.append(canon_tax_id(m.group(0)))
    # unique (keep order)
    seen=set(); out=[]
    for x in ids:
        if x and x not in seen: seen.add(x); out.append(x)
    return out

def open_sheet():
    creds_json = os.getenv("GOOGLE_CREDENTIALS_JSON")
    if not creds_json:
        raise RuntimeError("GOOGLE_CREDENTIALS_JSON is empty.")
    info = json.loads(creds_json)
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    gc = gspread.authorize(creds)
    sheet_id = os.getenv("SHEET_ID")
    if not sheet_id:
        raise RuntimeError("SHEET_ID not set.")
    sh = gc.open_by_key(sheet_id)
    ws = sh.get_worksheet(0)  # gid=0
    first = ws.row_values(1)
    if first != HEADERS:
        ws.resize(1)
        retry_backoff(lambda: ws.update("A1", [HEADERS]))
    return sh, ws

def build_taxid_rowindex(ws):
    """‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå A ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á map: tax_id ‚Üí row_index"""
    col = ws.col_values(1)  # ‡∏£‡∏ß‡∏° header
    idx = {}
    for i, v in enumerate(col[1:], start=2):
        t = canon_tax_id(v)
        if t:
            idx[t] = i
    return idx, len(col)  # last_row+1 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö append

class SheetBuffer:
    """
    ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞ upsert ‡πÄ‡∏õ‡πá‡∏ô batch:
      - updates: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ñ‡∏ß‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡πÉ‡∏ä‡πâ values_batch_update
      - inserts: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà ‚Üí ‡πÉ‡∏ä‡πâ values_append ‡∏ó‡∏µ‡∏•‡∏∞‡∏Å‡πâ‡∏≠‡∏ô
    """
    def __init__(self, sh, ws, row_index_map, batch_size=50):
        self.sh = sh
        self.ws = ws
        self.title = ws.title
        self.idx = row_index_map  # tax_id ‚Üí row
        self.batch_size = batch_size
        self.updates = []  # list of dict: {'range': 'Sheet1!A5:O5', 'values': [[...]]}
        self.inserts = []  # list of values rows (no range needed for append)
        self.next_append_row = ws.row_count + 1  # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏ú‡∏∑‡πà‡∏≠

    def add(self, row_dict):
        tax_id = canon_tax_id(row_dict["tax_id"])
        values = [row_dict.get(h, "") for h in HEADERS]
        values[0] = f"'{tax_id}"  # ‡∏Å‡∏±‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏´‡∏≤‡∏¢
        if tax_id in self.idx:
            r = self.idx[tax_id]
            a1 = f"{self.title}!A{r}:{chr(ord('A')+len(HEADERS)-1)}{r}"
            self.updates.append({"range": a1, "values": [values]})
        else:
            self.inserts.append(values)
        # flush ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡πâ‡∏≠‡∏ô
        if len(self.updates) + len(self.inserts) >= self.batch_size:
            self.flush()

    def flush(self):
        # 1) ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ range (‡∏ó‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡πÄ‡∏î‡∏¥‡∏°)
        if self.updates:
            data = [{"range": u["range"], "values": u["values"]} for u in self.updates]
            def do_update():
                return self.sh.values_batch_update(
                    data=data,
                    value_input_option="RAW"
                )
            retry_backoff(do_update)
            self.updates.clear()

        # 2) append ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        if self.inserts:
            def do_append():
                return self.sh.values_append(
                    range=f"{self.title}!A1",
                    params={"valueInputOption": "RAW", "insertDataOption": "INSERT_ROWS"},
                    body={"values": self.inserts}
                )
            retry_backoff(do_append)
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï index map ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏•‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á)
            # ‡πÄ‡∏Ñ‡∏™‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡πÄ‡∏•‡∏Ç row ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞ re-scan; ‡πÅ‡∏ï‡πà‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏î API calls ‡πÅ‡∏•‡πâ‡∏ß
            self.inserts.clear()

# ========== Main ==========
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--tax-id", default=os.getenv("TAX_ID", "0135563016845"))
    ap.add_argument("--list-file", default="tax_ids.txt")
    ap.add_argument("--out-dir", default="data")
    ap.add_argument("--limit", type=int, default=40, help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏ö (0=‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)")
    ap.add_argument("--offset", type=int, default=0, help="‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å (‡∏õ‡∏Å‡∏ï‡∏¥‡∏õ‡∏•‡πà‡∏≠‡∏¢ 0 ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ skip)")
    ap.add_argument("--skip-existing", choices=["none","sheet","json","both"], default="sheet",
                    help="‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô sheet/json")
    ap.add_argument("--batch-size", type=int, default=50, help="‡∏Ç‡∏ô‡∏≤‡∏î batch ‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Sheets ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    args = ap.parse_args()

    ids_all = read_tax_ids(args.list_file)
    if not ids_all:
        t = canon_tax_id(args.tax_id)
        if not re.fullmatch(r"\d{13}", t):
            print("‚ùå ‡πÉ‡∏™‡πà‡πÄ‡∏•‡∏Ç‡∏ú‡∏π‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏†‡∏≤‡∏©‡∏µ 13 ‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"); return
        ids_all = [t]

    os.makedirs(args.out_dir, exist_ok=True)
    sh, ws = open_sheet()

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πà‡∏≠‡∏ô ‚Üí slice ‡∏ï‡∏≤‡∏° limit/offset
    done = set()
    if args.skip_existing in ("sheet","both"):
        idx_map, _ = build_taxid_rowindex(ws)
        done |= set(idx_map.keys())
    else:
        idx_map, _ = build_taxid_rowindex(ws)

    from_json = set()
    if args.skip_existing in ("json","both"):
        if os.path.isdir(args.out_dir):
            from_json = {canon_tax_id(fn[:-5]) for fn in os.listdir(args.out_dir) if fn.endswith(".json")}
        done |= from_json

    remaining = [t for t in (canon_tax_id(x) for x in ids_all) if t not in done]
    start = max(args.offset, 0)
    end = (start + args.limit) if args.limit and args.limit > 0 else None
    ids = remaining[start:end]
    print(f"‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß {len(remaining)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‚Üí ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥ {len(ids)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    buf = SheetBuffer(sh, ws, idx_map, batch_size=args.batch_size)

    driver = build_driver()
    try:
        total = len(ids)
        for i, tax_id in enumerate(ids, start=1):
            print(f"\nüîé [{i}/{total}] ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏†‡∏≤‡∏©‡∏µ: {tax_id}")
            try:
                data = scrape_one_id(driver, tax_id)
            except Exception as e:
                print(f"‚ùå error: {e}")
                time.sleep(1.0)
                continue

            if not data:
                print("‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                canon = canon_tax_id(tax_id)
                row = {
                    "tax_id": canon,
                    **data,
                    "fetched_at_utc": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
                }
                fp = os.path.join(args.out_dir, f"{canon}.json")
                with open(fp, "w", encoding="utf-8") as f:
                    json.dump(row, f, ensure_ascii=False, indent=2)
                print(f"üíæ saved: {fp}")

                # ===== ‡πÉ‡∏ä‡πâ batch buffer ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£ upsert ‡∏ó‡∏µ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß =====
                buf.add(row)
                print("üìù queued for batch write")

            time.sleep(random.uniform(1.0, 2.0))
    finally:
        try:
            driver.quit()
        except Exception:
            pass
        # flush ‡∏á‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏ö
        print("\nüöÄ flush batch to Google Sheets ...")
        buf.flush()
        print("‚úÖ done")

if __name__ == "__main__":
    time.sleep(random.uniform(1.2, 2.5))
    main()
