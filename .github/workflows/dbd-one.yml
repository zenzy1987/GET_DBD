name: dbd-one

permissions:
  contents: write

on:
  workflow_dispatch:
    inputs:
      lines_per_chunk:
        description: "จำนวนบรรทัดต่อชิ้น (chunk) ใน tax_ids.txt"
        required: false
        default: "50"
      limit:
        description: "จำนวนต่อรอบที่ python จะประมวลผล (0=ทั้งหมดใน chunk)"
        required: false
        default: "0"
      skip_existing:
        description: "none/sheet/json/both (แนะนำ: sheet)"
        required: false
        default: "sheet"
      batch_size:
        description: "จำนวนแถวต่อการเขียนลงชีท 1 ครั้ง (batch)"
        required: false
        default: "50"
  schedule:
    - cron: "*/15 * * * *"   # รันทุก 15 นาที (UTC)

concurrency:
  group: dbd-one-${{ github.ref }}
  cancel-in-progress: false

jobs:
  prep:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.make-matrix.outputs.matrix }}
      lines_per_chunk: ${{ steps.vars.outputs.lines }}
      limit: ${{ steps.vars.outputs.limit }}
      skip: ${{ steps.vars.outputs.skip }}
      batch: ${{ steps.vars.outputs.batch }}
    steps:
      - uses: actions/checkout@v4

      - name: Ensure jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - id: vars
        run: |
          echo "lines=${{ github.event.inputs.lines_per_chunk || '50' }}" >> $GITHUB_OUTPUT
          echo "limit=${{ github.event.inputs.limit || '0' }}" >> $GITHUB_OUTPUT
          echo "skip=${{ github.event.inputs.skip_existing || 'sheet' }}" >> $GITHUB_OUTPUT
          echo "batch=${{ github.event.inputs.batch_size || '50' }}" >> $GITHUB_OUTPUT

      - name: Split tax_ids.txt into chunks
        run: |
          set -euo pipefail
          LINES="${{ steps.vars.outputs.lines }}"
          mkdir -p chunks
          touch tax_ids.txt
          split -l "$LINES" -d -a 3 tax_ids.txt chunks/chunk_
          ls -l chunks || true

      - id: make-matrix
        name: Build matrix from chunks
        run: |
          set -euo pipefail
          files=$(ls -1 chunks/chunk_* 2>/dev/null || true)
          if [ -z "$files" ]; then
            echo "" > chunks/chunk_000
            files="chunks/chunk_000"
          fi
          MATRIX=$(printf "%s\n" $files | jq -R -s -c 'split("\n")[:-1]')
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "matrix=$MATRIX"

      - name: Upload chunks (for debugging)
        uses: actions/upload-artifact@v4
        with:
          name: taxid-chunks
          path: chunks/*

  run-chunks:
    needs: prep
    runs-on: ubuntu-latest
    timeout-minutes: 25
    strategy:
      fail-fast: false
      matrix:
        chunk: ${{ fromJSON(needs.prep.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Setup Chrome
        id: chrome
        uses: browser-actions/setup-chrome@v1

      - name: Remove stale chromedriver in PATH
        run: sudo rm -f /usr/bin/chromedriver || true

      - name: Install dependencies
        run: |
          python -m pip install -U pip wheel setuptools
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # ต้องมีตามโค้ดใหม่ (ไม่ต้องใช้ googleapiclient)
          pip install --upgrade gspread google-auth beautifulsoup4 selenium

      - name: Sanity check imports
        run: |
          python - <<'PY'
          import gspread
          from bs4 import BeautifulSoup
          import selenium
          print("✅ imports ok")
          PY

      - name: Download chunk file from artifact (fallback)
        uses: actions/download-artifact@v4
        with:
          name: taxid-chunks
          path: chunks

      - name: Run DBD batch → Google Sheets (per-chunk)
        env:
          CHROME_PATH: ${{ steps.chrome.outputs.chrome-path }}
          CHROME_BIN:  ${{ steps.chrome.outputs.chrome-path }}
          GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
          SHEET_ID: ${{ vars.SHEET_ID }}
          PYTHONUNBUFFERED: "1"
        run: |
          set -euo pipefail
          CHUNK="${{ matrix.chunk }}"
          LIMIT="${{ needs.prep.outputs.limit }}"
          SKIP="${{ needs.prep.outputs.skip }}"
          BATCH="${{ needs.prep.outputs.batch }}"

          echo "▶ Running chunk: $CHUNK  limit=$LIMIT  skip=$SKIP  batch=$BATCH"

          ( while true; do echo "⏱ $(date -u +%H:%M:%SZ) still running (chunk $CHUNK)..."; sleep 60; done ) &
          HB=$!

          ARGS=( --list-file "$CHUNK" --limit "$LIMIT" --offset "0" --skip-existing "$SKIP" --batch-size "$BATCH" )

          timeout 22m python -u dbd_one.py "${ARGS[@]}" | tee "result_${{ strategy.job-index }}.txt"
          RC=${PIPESTATUS[0]}
          kill "$HB" || true

          {
            echo "### Chunk: $CHUNK (last 200 lines)"
            tail -n 200 "result_${{ strategy.job-index }}.txt" || true
          } >> "$GITHUB_STEP_SUMMARY"

          exit $RC

      - name: Commit JSON results to repo (safe with retry)
        env:
          GH_EMAIL: 41898282+github-actions[bot]@users.noreply.github.com
          GH_NAME: github-actions[bot]
        run: |
          set -e
          git config user.name  "$GH_NAME"
          git config user.email "$GH_EMAIL"
          git add -A data || true
          if ! git diff --cached --quiet -- data; then
            n=0
            until [ $n -ge 5 ]; do
              git commit -m "DBD batch ${GITHUB_RUN_ID} chunk:${{ matrix.chunk }}"
              git pull --rebase --autostash origin "${{ github.ref_name }}" || true
              if git push origin HEAD:"${{ github.ref_name }}"; then
                echo "✅ pushed"
                break
              fi
              echo "⏳ push failed; retrying..."
              n=$((n+1))
              sleep 3
            done
          else
            echo "Nothing to commit"
          fi

      - name: Upload JSONs as artifact (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dbd-json-${{ strategy.job-index }}
          path: data/*.json
          if-no-files-found: ignore
